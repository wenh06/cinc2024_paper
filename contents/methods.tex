\section{Methods}
\label{sec:methods}

% almost finished

\subsection{Data Prosessing}
\label{subsec:data_processing}

% almost finished

The Challenge did not provide any ECG images directly for method development. Instead, it offered a tool named ECG-Image-Kit \cite{Shivashankara_2024_ECG} to generate ECG images from digital ECG signals. We utilized this tool on the PTB-XL dataset \cite{wagner2020ptb_xl} and generated a total of 21,799 synthetic ECG images for method development. Additionally, the PTB-XL+ dataset \cite{Strodthoff_2023} was used to generate classification labels for the ECG images.

The image generation setup included augmentations such as random Gaussian noise, random color temperature adjustments, and distortions including handwritten notes, wrinkles, and creases. Bounding boxes for the printed ECG waveforms and lead names, along with the plotted pixel coordinates of the ECG waveforms, were recorded in metadata files alongside the generated images. These supplementary data were used to:
\begin{itemize}
\item[(1)] Train the object detection model to detect the bounding boxes of the ECG waveforms and lead names in the ECG images, thus identifying the region of interest (ROI) for subsequent ECG signal extraction.
\item[(2)] Train the segmentation model to digitize the ECG waveforms from the images.
\end{itemize}

The PTB-XL dataset assigned a ``strat\_fold'' property (with values 1-10) to each record, which we used to split the dataset into training, and validation sets. The validation set has ``strat\_fold'' values 10, as recommended by the PTB-XL dataset, serving for model selection and hyperparameter tuning. The training set comprises the remaining records.

\newif\ifFrameworkFigBox
\FrameworkFigBoxtrue

\begin{figure*}[!ht]
\centering
\input{tikz_plots/multi-stage-framework.tex}
\caption{The multi-stage framework for simultaneous digitization and classification of ECG images.}
\label{fig:multi-stage-framework}
\end{figure*}

\subsection{The Multi-Stage Framework}
\label{subsec:multi_stage_framework}

% almost finished

To simultaneously digitize and classify ECG images, we designed a multi-stage framework, as shown in Figure \ref{fig:multi-stage-framework}. The framework comprises three deep learning-based modules: object detection, segmentation, and classification.

The object detection module identifies the bounding boxes of the ECG waveforms and lead names in the ECG images, thereby determining the region of interest (ROI) for subsequent ECG signal extraction and classification. This module constitutes the first stage of the framework.

The segmentation module extracts a mask of the ECG waveforms from the ROI, which is then transformed into digitized values based on the pixel coordinates of the predicted mask. The bounding boxes obtained from the object detection module are also used to separate the ECG waveforms at different horizontal positions. In cases where the bounding boxes overlap, which commonly occurs when the ECG signals have large amplitudes, we employ a 4-cluster K-means algorithm on the y-coordinates of the predicted mask to locate the isoelectric line of the ECG waveforms and then perform the separation. Concurrently, the classification module predicts the classes of the ECG waveforms from the ROI. Together, these two modules constitute the second stage of the framework.

\subsection{Model Selection}
\label{subsec:model_selection}

% almost finished

We present our criteria for selecting the deep learning models for the three modules discussed in Section \ref{subsec:multi_stage_framework}. The models are chosen based on their performance, efficiency, and compatibility with ECG image data. After evaluating several models, we choose the following models for the three modules:
\begin{itemize}
\item[(1)] Object Detection: A DETR model \cite{carion2020DETR} with a ResNet-50 backbone \cite{resnet}.
\item[(2)] Classification: A lightweight ConvNeXt model \cite{Liu_2022_ConvNeXt} of ``nano'' size.
\item[(3)] Segmentation: A U-Net model \cite{unet}.
\end{itemize}
The object detection model and the classification model are trained from a pre-trained model loaded from Huggingface's model hub \cite{wolf-etal-2020-transformers}, while the segmentation model is trained from scratch. The models are implemented and trained using the ``torch\_ecg'' library \cite{torch_ecg_paper}. The sizes in terms of the number of trainable parameters of the selected models are listed in Table \ref{tab:model_num_params}.

\begin{table}[!htp]
\centering
\input{tables/model_num_params.tex}
\caption{Number of trainable parameters in the models.}
\label{tab:model_num_params}
\end{table}

It is important to note that for the classification model, using an oversized model may not improve the performance and can even degrade it due to overfitting. Therefore, we opted for a lightweight model to balance performance and efficiency. The evaluation metrics (in terms of F1 score) of different sizes of ConvNeXt models on the left-out validation set, along with their number of trainable parameters, are presented in Table \ref{tab:clf_selection}.

\begin{table}[!htp]
\centering
\input{tables/classifier_selection.tex}
\caption{Evaluation metrics of ConvNeXt models of different sizes. The values are F1 scores on the left-out validation set. The threshold refers to the probability threshold for the multi-label predictions. ``head only'' refers to the model with backbone weights frozen. The last row shows the number of trainable parameters in each model.}
\label{tab:clf_selection}
\end{table}

The DETR model achieved a mean average precision (mAP) of $0.90$ and the U-Net model achieved a Dice coefficient of $0.73,$ both on the left-out validation set.

\subsection{Loss Functions}
\label{subsec:loss_functions}

% almost finished

\begin{figure}[!htp]
\centering
\includegraphics[width=\linewidth]{images/data_distribution.pdf}
\caption{Data distribution of the PTB-XL dataset. Labels are generated from the PTB-XL+ dataset. Abbreviations: NORM, Normal; OLD MI, Old Myocardial Infarction; STTC, ST/T Changes; CD, Conduction Disturbances; HYP, Hypertrophy; PVC, Premature Ventricular Complex; Acute MI, Acute Myocardial Infarction; AFIB/AFL, Atrial Fibrillation/Atrial Flutter; PAC, Premature Atrial Complex; TACHY, Tachycardia.}
\label{fig:data-distribution}
\end{figure}

Given the highly imbalanced data distribution for the classification problem, as illustrated in Figure \ref{fig:data-distribution}, and the multi-label nature of the task, we adopted the asymmetric loss function \cite{ridnik2021asymmetric_loss}. The asymmetric loss is defined in Equation \eqref{eq:asymmetric_loss}.
\begin{equation}
\label{eq:asymmetric_loss}
\begin{array}{ll}
& L = -y \cdot (1-p)^{\gamma_{+}} \log(p) \\
& \phantom{L = } - (1-y) \cdot (p_m)^{\gamma_{-}} \log(1-p_m), \\
\text{where} & p_m = \max(p - m, 0),
\end{array}
\end{equation}
where $y$ is the ground truth label, $p$ is the predicted probability, $m$ is the probability margin, and $\gamma_{+}$ and $\gamma_{-}$ are the positive and negative focusing parameters, respectively. The margin $m$ and the focusing parameters $\gamma_{+}$ and $\gamma_{-}$ are hyperparameters that can be tuned. We set $\gamma_{+} = 1,$ $\gamma_{-} = 4,$ and $m = 0.05$ in our experiments.

For the segmentation task, considering that the ECG waveforms occupy only a small portion of the image, we used the binary cross-entropy loss multiplied by a weight mask to balance the loss contribution from different parts of the ECG waveforms. The weight mask is the sum of multiple dilations (for example, dilation iterations 2, 4, 6, and 8) of the binarized ground truth mask. An example of the weight mask is shown in Figure \ref{fig:weight-mask}.

\begin{figure}[!htp]
\centering
\includegraphics[width=\linewidth]{images/weight-mask.pdf}
\caption{An example of the weight mask for the segmentation loss function.}
\label{fig:weight-mask}
\end{figure}

For the object detection task, we used the standard DETR loss function, which is a linear combination of the cross-entropy loss for the bounding box class predictions (with a coefficient of 1) and the bounding box coordinate regression loss (L1 loss with a coefficient of 5 and generalized IoU loss with a coefficient of 2).

% \subsection{Training Details}
% \label{subsec:training_details}

% % NOT finished
